{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise made by: Happy County\n",
    "\n",
    "### Exercise 1 - Regex\n",
    "\n",
    "Link: https://github.com/AndreasVikke/CPH-Business-Python/blob/master/Week9/WeekExcersies/ip-logfile.log\n",
    "\n",
    "Use regex on the data to get every different ip save the ipâ€™s in a list.\n",
    "\n",
    "Hint! Data is a CSV file, save regex result to a set to easy deal with duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'21.15.46.55', '213.179.54.190', '2.33.66.07', '162.247.74.217', '217.170.205.107', '68.184.5.12', '199.249.230.69', '3.95.29.25', '19.2.45.3', '199.249.230.123', '108.87.82.181', '2.12.51.56', '185.107.47.171', '185.220.101.25', '7.59.4.07', '27.02.48.11', '4.96.46.65', '69.31.21.2', '2.2.82.64', '139.99.172.11', '185.220.102.4', '216.151.180.191', '174.130.215.196', '193.31.53.501', '50.35.73.6', '1.23.82.72', '89.163.239.216', '5.199.130.188', '209.141.34.95', '185.220.101.6', '193.218.118.90', '3.42.31.69', '185.220.101.57'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import webget\n",
    "\n",
    "ip_list = []\n",
    "\n",
    "url = 'https://github.com/AndreasVikke/CPH-Business-Python/blob/master/Week9/WeekExcersies/ip-logfile.log'\n",
    "webget.download(url)\n",
    "\n",
    "with open('ip-logfile.log') as file:\n",
    "    contents = file.read()\n",
    "    \n",
    "pattern = re.compile(r'\\d+[.]\\d+[.]\\d+[.]\\d+')\n",
    "result = pattern.findall(contents)\n",
    "\n",
    "for ip in result:\n",
    "    ip_list.append(ip)\n",
    "    ip_set = set(ip_list)\n",
    "    \n",
    "print(ip_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2 - Selenium\n",
    "\n",
    "Use selenium(or hint) to paste an ip from the list to: https://www.whois.com/whois/ and get NetName, NetRange, OrgName, Address, City, StateProv, PostalCode Country, RegDate.\n",
    "\n",
    "Hint! You can use https://whois.whoisxmlapi.com/ instead of selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ip': '68.184.5.12', 'Net-name': 'CLNTN-MO-68-184-0', 'Net-range': '68.184.0.0 - 68.184.15.255', 'Org-name': 'Charter Communications', 'Address': '6399 S Fiddlers Green Circle', 'City': 'Greenwood Village', 'State-prov': 'CO', 'Postal-code': '80111', 'Country': 'US', 'Reg-date': '2003-01-02'}\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "browser = webdriver.Chrome('./chromedriver')\n",
    "browser.get('https://www.whois.com/whois/')\n",
    "\n",
    "ip = ip_list[random.randint(0,len(ip_set)-1)]\n",
    "\n",
    "browser.find_element_by_id(\"query\").send_keys(ip)\n",
    "browser.find_element_by_tag_name(\"button\").click()\n",
    "\n",
    "text = browser.find_element_by_tag_name(\"pre\").text\n",
    "\n",
    "information = {}\n",
    "\n",
    "information[\"ip\"] = ip\n",
    "\n",
    "def get_attribute(pattern, name, group):\n",
    "    compiler = re.compile(pattern)\n",
    "    search = compiler.search(text)\n",
    "    if search is None:\n",
    "        information[name] = None\n",
    "    else:\n",
    "        information[name] = search.group(group)\n",
    "\n",
    "get_attribute(r'(n|N)et(n|N)ame: *(.*)', 'Net-name', 3)\n",
    "get_attribute(r'(n|N)et(r|R)ange: *(.*)', 'Net-range', 3)\n",
    "get_attribute(r'(o|O)rg(n|N)ame: *(.*)', 'Org-name', 3)\n",
    "get_attribute(r'(a|A)ddress: *(.*)', 'Address', 2)\n",
    "get_attribute(r'City: *(.*)', 'City', 1)\n",
    "get_attribute(r'StateProv: *(.*)', 'State-prov', 1)\n",
    "get_attribute(r'PostalCode: *(.*)', 'Postal-code', 1)\n",
    "get_attribute(r'Country: *(.*)', 'Country', 1)\n",
    "get_attribute(r'(r|R)eg(d|D)ate: *(.*)', 'Reg-date', 3)\n",
    "                      \n",
    "print(information)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3 - Data persistence and Web services\n",
    "\n",
    "Store some of the data in a database with PyMySQL and create a flask server with a GET endpoint to show all the data stored in the DB. (Optionally deploy flask server on your droplet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql as sql\n",
    "\n",
    "cnx = sql.connect(user='dev', password='ax2',host='127.0.0.1',port=3307,db='python')\n",
    "\n",
    "def persist_data(connector, dictionary, table_name):\n",
    "    \n",
    "    cursor = cnx.cursor(sql.cursors.DictCursor)\n",
    "    #cursor.execute(\"CREATE TABLE week9 (ip VARCHAR(255), net_name VARCHAR(255), net_range VARCHAR(255), org_name VARCHAR(255), address VARCHAR(255), city VARCHAR(255), state_prov VARCHAR(255), postal_code VARCHAR(255), country VARCHAR(255), reg_date VARCHAR(255))\")\n",
    "    add_info = (\"INSERT INTO week9 (ip, net_name, net_range, org_name, address, city, state_prov, postal_code, country, reg_date) VALUES (%(ip)s, %(Net-name)s, %(Net-range)s, %(Org-name)s, %(Address)s, %(City)s, %(State-prov)s, %(Postal-code)s, %(Country)s, %(Reg-date)s)\")\n",
    "    \n",
    "    cursor.execute(add_info, information)\n",
    "    cnx.commit()\n",
    "    cursor.close()\n",
    "    cnx.close()\n",
    "\n",
    "persist_data(cnx, information, 'week9')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
